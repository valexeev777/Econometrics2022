{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ae4ca0-6298-40d9-b74d-26ca7ef30c67",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "# Step by step hands-on tutorial with practical examples\n",
    "\n",
    "Hypotheses are claims, and we can use statistics to prove or disprove them. At this point, hypothesis testing structures the problems so that we can use statistical evidence to test these claims. So we can check whether or not the claim is valid.\n",
    "\n",
    "## 1. Defining Hypotheses\n",
    "\n",
    "First of all, we should understand which scientific question we are looking for an answer to, and it should be formulated in the form of the **Null Hypothesis** ($H_0$) and the **Alternative Hypothesis** ($H_1$ or $H_a$). Please remember that $H_0$ and $H_1$ must be mutually exclusive, and $H_1$ shouldn't contain equality:\n",
    "\n",
    "- $H_0$: $\\mu=x$, $H_1$: $\\mu\\neq x$ (two-tailed test)\n",
    "- $H_0$: $\\mu\\leq x$, $H_1$: $\\mu> x$\n",
    "- $H_0$: $\\mu\\geq x$, $H_1$: $\\mu< x$\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "To decide whether to use the **parametric** or **nonparametric** version of the test, we should check the specific requirements listed below:\n",
    "\n",
    "- Observations in each sample are independent and identically distributed (IID/i.i.d./iid).\n",
    "- Observations in each sample are normally distributed.\n",
    "- Observations in each sample have the same variance.\n",
    "\n",
    "## 3. Selecting the Proper Test\n",
    "\n",
    "Then we select the appropriate test to be used. When choosing the proper test, it is essential to analyze how many groups are being compared and whether the data are paired or not. To determine whether the data is matched, it is necessary to consider whether the data was collected from the same individuals. Accordingly, you can decide on the appropriate test using the chart below.\n",
    "\n",
    "<img src=\"HypothesisTesting01.png\" alt=\"Alt text that describes the graphic\" title=\"Python data types\" style=\"width: 800px;\"/>\n",
    "\n",
    "\n",
    "## 4. Decision and Conclusion\n",
    "\n",
    "After performing the hypothesis testing, we obtain a related **p-value** that shows the significance of the test.\n",
    "\n",
    "If the p-value is smaller than the **alpha** (the significance level), in other words, there is enough evidence to prove $H_0$ is not valid; you can reject $H_0$. Otherwise, you **fail to reject** $H_0$ (do not use the term \"accept\", instead use \"fail to reject\"). Please remember that rejecting $H_0$ validates $H_1$. However, failing to reject $H_0$ does not mean $H_0$ is valid, nor does it mean $H_1$ is wrong.\n",
    "\n",
    "<img src=\"HypothesisTesting02.png\" alt=\"Alt text that describes the graphic\" title=\"Python data types\" style=\"width: 600px;\"/>\n",
    "\n",
    "\n",
    "Now we are ready to start the code part.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "546657f2-4abf-4b22-bd7c-8d94c544db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install scikit_posthocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "84747679-e488-402d-b9ca-7e76e226759c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikit_posthocs as sp\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:,.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e0a51d8-1556-4800-aad1-75c384e5a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normality(data):\n",
    "    test_stat_normality, p_value_normality=stats.shapiro(data)\n",
    "    print(\"p value:%.4f\" % p_value_normality)\n",
    "    if p_value_normality <0.05:\n",
    "        print(\"Reject null hypothesis >> The data are not normally distributed\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The data are normally distributed\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54858e8d-eafa-4201-b23c-487e0d30bb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variance_homogeneity(group1, group2):\n",
    "    test_stat_var, p_value_var= stats.levene(group1,group2)\n",
    "    print(\"p value:%.4f\" % p_value_var)\n",
    "    if p_value_var <0.05:\n",
    "        print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "    else:\n",
    "        print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5baa57d-188b-43eb-be03-36b08c3f4ac1",
   "metadata": {},
   "source": [
    "# Q1. t-test independent\n",
    "\n",
    "A university professor gave online lectures instead of face-to-face classes due to Covid-19. Later, he uploaded recorded lectures to the cloud for students who followed the course asynchronously (those who did not attend the lesson but later watched the records). However, he believes that the students who attend class at the class time and participate in the process are more successful. Therefore, he recorded the average grades of the students at the end of the semester. The data is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d46681ef-5578-4f90-b88f-bcb623b12eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sync = np.array([94. , 84.9, 82.6, 69.5, 80.1, 79.6, 81.4, 77.8, 81.7, 78.8, 73.2,\n",
    "       87.9, 87.9, 93.5, 82.3, 79.3, 78.3, 71.6, 88.6, 74.6, 74.1, 80.6])\n",
    "asyncr =np.array([77.1, 71.7, 91. , 72.2, 74.8, 85.1, 67.6, 69.9, 75.3, 71.7, 65.7, 72.6, 71.5, 78.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e1e795-5ec0-43c0-8fd8-c8fc61ef3bbe",
   "metadata": {},
   "source": [
    "**Conduct the hypothesis testing to check whether the professor's belief is statistically significant by using a 0.05 significance level to evaluate the null and alternative hypotheses. Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f18ab-6131-4d17-bb35-1663bd572a75",
   "metadata": {},
   "source": [
    "$H_{0}$: The data is normally distributed.  \n",
    "$H_{1}$: The data is not normally distributed.   \n",
    "\n",
    "Assume that $\\alpha=0.05$ If $p$-value is >0.05, it can be said that data is normally distributed.\n",
    "\n",
    "For checking normality, I used **Shapiro-Wilk's W test** which is generally preferred for smaller samples however there are other options like **Kolmogorov-Smirnov** and **D'Agostino and Pearson's test**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f70f637f-115e-44b1-b0aa-8b3daee6a31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.6556\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n",
      "p value:0.0803\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(sync)\n",
    "check_normality(asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa160f-9346-4d70-834a-d003019cf6c0",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are same.  \n",
    "$H_{1}$: The variances of the samples are different.\n",
    "    \n",
    "It tests the null hypothesis that the population variances are equal (called homogeneity of variance or homoscedasticity). If the resulting p-value of [**Levene's test**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.levene.html?highlight=levene#scipy.stats.levene) is less than some significance level (typically 0.05), the obtained differences in sample variances are unlikely to have occurred based on random sampling from a population with equal variances.\n",
    "\n",
    "For checking variance homogeneity, I preferred **Levene's test** but you can also check [**Bartlett's test**](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.bartlett.html#scipy.stats.bartlett)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c538844a-009f-494a-8100-b8f1823f7f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.8149\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "check_variance_homogeneity(sync, asyncr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bafe332-9698-4cd0-938c-361e7d5d6ac5",
   "metadata": {},
   "source": [
    "## 1. Defining Hypothesis\n",
    "\n",
    "Since the grades are obtained from the different individuals, the data is unpaired.\n",
    "\n",
    "$H_{0}$: $\\mu_{s}<= \\mu_{a}$     \n",
    "$H_{1}$: $\\mu_{s}>  \\mu_{a}$\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "We verified hat our data are normally distributed and that the variances of the samples are the same. \n",
    "\n",
    "## 3. Selecting the Proper Test\n",
    "\n",
    "Since assumptions are satisfied, we can perform the parametric version of the test for 2 groups and unpaired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44e803a1-e7ae-4279-b15a-68f49e376188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.00753598\n",
      "since the hypothesis is one sided >> use p_value/2 >> p_value_one_sided:0.0038\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest,p_value = stats.ttest_ind(sync,asyncr)\n",
    "print(\"p value:%.8f\" % p_value)\n",
    "print(\"since the hypothesis is one sided >> use p_value/2 >> p_value_one_sided:%.4f\" %(p_value/2))\n",
    "if p_value/2 <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54456b50-6477-4fee-a110-fe9c622d43a4",
   "metadata": {},
   "source": [
    "## 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, there is enough evidence to conclude that the average grade of the students who follow the course synchronously is higher than the students who follow the course asynchronously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76293717-9dbc-41a8-8a54-1dde6d84aacc",
   "metadata": {},
   "source": [
    "# Q2. ANOVA\n",
    "\n",
    "A pediatrician wants to see the effect of formula consumption on the average monthly weight gain (in gr) of babies. For this reason, she collected data from three different groups. The first group is exclusively breastfed children (receives only breast milk), the second group is children who are fed with only formula and the last group is both formula and breastfed children. These data are as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8078410-0d21-4302-8014-8a1bcdecba53",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_breast=np.array([794.1, 716.9, 993. , 724.7, 760.9, 908.2, 659.3 , 690.8, 768.7,\n",
    "       717.3 , 630.7, 729.5, 714.1, 810.3, 583.5, 679.9, 865.1])\n",
    "\n",
    "only_formula=np.array([ 898.8,  881.2,  940.2,  966.2,  957.5, 1061.7, 1046.2,  980.4,\n",
    "        895.6,  919.7, 1074.1,  952.5,  796.3,  859.6,  871.1 , 1047.5,\n",
    "        919.1 , 1160.5,  996.9])\n",
    "\n",
    "both=np.array([976.4, 656.4, 861.2, 706.8, 718.5, 717.1, 759.8, 894.6, 867.6,\n",
    "       805.6, 765.4, 800.3, 789.9, 875.3, 740. , 799.4, 790.3, 795.2 ,\n",
    "       823.6, 818.7, 926.8, 791.7, 948.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5823fd1-44fb-41dc-9915-856da1b88970",
   "metadata": {},
   "source": [
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the average monthly gain of these three groups by using a 0.05 significance level. If there is a significant difference, perform further analysis to find what caused the difference.**\n",
    "\n",
    "Before doing hypothesis testing, check the related assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ccaef3-5b33-4bf9-94c5-3e58922dad3b",
   "metadata": {},
   "source": [
    "## 1. Defining Hypothesis\n",
    "\n",
    "$H_0$: $\\mu_1=\\mu_2=\\mu_3$ (The means of the samples are the same).<br>\n",
    "$H_1$: At least one of them is different.\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "$ H_{0} $: The data are normally distributed.  \n",
    "$ H_{1} $: The data are not normally distributed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8964711-f756-4adb-9bb7-ac749a1d9892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.4694\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n",
      "p value:0.8879\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n",
      "p value:0.7973\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(only_breast)\n",
    "check_normality(only_formula)\n",
    "check_normality(both)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa62a0f-2bdf-46fe-ac42-b6816aa14a2a",
   "metadata": {},
   "source": [
    "$H_{0}$: The variances of the samples are the same.  \n",
    "$H_{1}$: The variances of the samples are different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0bd771d0-2436-4408-9f4b-895379483108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.7673\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(only_breast,only_formula,both)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0cf566-58b1-4549-a8cb-d70d1c1885d1",
   "metadata": {},
   "source": [
    "## 3. Selecting the Proper Test\n",
    "\n",
    "Since assumptions are satisfied, we can perform the parametric version of the test for more than 2 groups and unpaired data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "308fb510-3152-468a-9b5d-94dc3aa3c96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000000\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.f_oneway(only_breast,only_formula,both)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a93aef-bf0f-4f46-bb4e-0edd666f1dd2",
   "metadata": {},
   "source": [
    "## 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, it can be concluded that at least one of the groups has a different average monthly weight gain. To find which group or groups cause the difference, we need to perform a posthoc test/pairwise comparison as below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f98dd29-2ec2-40ea-8816-8af68f156ac2",
   "metadata": {},
   "source": [
    "Note: To avoid family-wise $p$-value inflation, I used Bonferroni adjustment. You can see your other alternative from [here](https://scikit-posthocs.readthedocs.io/en/latest/generated/scikit_posthocs.posthoc_ttest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab44daf7-bea6-4cc9-af41-8004f024e44f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_88813_row0_col0, #T_88813_row0_col2, #T_88813_row1_col1, #T_88813_row2_col0, #T_88813_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_88813_row0_col1, #T_88813_row1_col0, #T_88813_row1_col2, #T_88813_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_88813\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_88813_level0_col0\" class=\"col_heading level0 col0\" >only breast</th>\n",
       "      <th id=\"T_88813_level0_col1\" class=\"col_heading level0 col1\" >only formula</th>\n",
       "      <th id=\"T_88813_level0_col2\" class=\"col_heading level0 col2\" >both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_88813_level0_row0\" class=\"row_heading level0 row0\" >only breast</th>\n",
       "      <td id=\"T_88813_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_88813_row0_col1\" class=\"data row0 col1\" >0.000000</td>\n",
       "      <td id=\"T_88813_row0_col2\" class=\"data row0 col2\" >0.129454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88813_level0_row1\" class=\"row_heading level0 row1\" >only formula</th>\n",
       "      <td id=\"T_88813_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_88813_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_88813_row1_col2\" class=\"data row1 col2\" >0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_88813_level0_row2\" class=\"row_heading level0 row2\" >both</th>\n",
       "      <td id=\"T_88813_row2_col0\" class=\"data row2 col0\" >0.129454</td>\n",
       "      <td id=\"T_88813_row2_col1\" class=\"data row2 col1\" >0.000004</td>\n",
       "      <td id=\"T_88813_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24232e94df0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pairwise T test for multiple comparisons of independent groups. May be used after a parametric ANOVA to do pairwise comparisons.\n",
    "\n",
    "import scikit_posthocs as sp\n",
    "posthoc_df= sp.posthoc_ttest([only_breast,only_formula,both], equal_var=True, p_adjust=\"bonferroni\")\n",
    "\n",
    "group_names= [\"only breast\", \"only formula\",\"both\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0a15e-ed5b-46a2-a659-31093869f87b",
   "metadata": {},
   "source": [
    "At this significance level, it can be concluded that:\n",
    "\n",
    "- \"only breast\" is different than \"only formula\"\n",
    "- \"only formula\" is different than both \"only breast\" and \"both\"\n",
    "- \"both\" is different than \"only formula\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc0fa4d-18db-4e57-9f59-7898135adf3c",
   "metadata": {},
   "source": [
    "# Q3. Mann Whitney U\n",
    "\n",
    "\n",
    "A human resource specialist working in a technology company is interested in the overwork time of different teams. To investigate whether there is a difference between overtime of the software development team and the test team, she selected 17 employees randomly in each of the two teams and recorded their weekly average overwork time in terms of an hour. The data are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dcd593fe-caa7-4510-aca5-74f197fadd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_team=np.array([6.2,  7.1,  1.5,  2,3 ,  2,  1.5,  6.1,  2.4,  2.3, 12.4,  1.8,  5.3,  3.1, 9.4,  2.3, 4.1])\n",
    "developer_team=np.array([2.3,  2.1,  1.4,  2.0, 8.7,  2.2,  3.1,  4.2,  3.6, 2.5,  3.1,  6.2, 12.1,  3.9,  2.2, 1.2 ,3.4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fa1e92-d721-49b3-bd81-41717d0daa4c",
   "metadata": {},
   "source": [
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the overwork time of two teams by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5b3075-deb3-49d7-aa9a-4ad54c461a2a",
   "metadata": {},
   "source": [
    "## 1. Defining Hypothesis\n",
    "\n",
    "$H_0$: $\\mu_1 \\leq \\mu_2$\n",
    "$H_1$: $\\mu_1 > \\mu_2$\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "$H_0$: The data is normally distributed.<br>\n",
    "$H_1$: The data is not normally distributed.<br>\n",
    "\n",
    "$H_0$: The variances of the samples are the same.<br>\n",
    "$H_1$: The variances of the samples are different.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0db31b5c-b2c3-454f-b14e-710d6d4078ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0046\n",
      "Reject null hypothesis >> The data are not normally distributed\n",
      "p value:0.0005\n",
      "Reject null hypothesis >> The data are not normally distributed\n",
      "p value:0.5410\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_team)\n",
    "check_normality(developer_team)\n",
    "check_variance_homogeneity(test_team, developer_team)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018b89b-c086-43cc-890f-f0cbd8cad4b2",
   "metadata": {},
   "source": [
    "## 3. Selecting the Proper Test\n",
    "\n",
    "There are two groups, and data is collected from different individuals, so it is not paired. However, the normality assumption is not satisfied; therefore, we need to use the nonparametric version of 2 group comparison for unpaired data: the Mann-Whitney U Test.\n",
    "\n",
    "$H_{0}$: $\\mu_{1}= \\mu_{2}$  **or** $\\mu_{1}- \\mu_{2} = 0 $  **or** The mean of the samples are same.      \n",
    "$H_{1}$: $\\mu_{1} \\neq \\mu_{2}$  **or** $\\mu_{1}- \\mu_{2} \\neq 0 $  **or** The mean of the samples are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a899c95a-208a-4be3-bfae-ce0d0ff1b3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.8226\n",
      "Fail to recejt null hypothesis\n"
     ]
    }
   ],
   "source": [
    "ttest,pvalue = stats.mannwhitneyu(test_team,developer_team, alternative=\"two-sided\")\n",
    "print(\"p-value:%.4f\" % pvalue)\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to recejt null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8999ab0-9acf-4784-9d48-86979a59ef53",
   "metadata": {},
   "source": [
    "## 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, it can be said that there is no statistically significant difference between the average overwork time of the two teams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceebf2bd-d84d-41dd-9304-f8d6496900e0",
   "metadata": {},
   "source": [
    "# Q4. Kruskal-Wallis\n",
    "\n",
    "An e-commerce company regularly advertises on YouTube, Instagram, and Facebook for its campaigns. However, the new manager was curious about if there was any difference between the number of customers attracted by these platforms. Therefore, she started to use Adjust, an application that allows you to find out where your users come from. The daily numbers reported from Adjust for each platform are as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "379eab3a-4c55-4d45-a786-9ec1a4eebcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube=np.array([1913, 1879, 1939, 2146, 2040, 2127, 2122, 2156, 2036, 1974, 1956,\n",
    "       2146, 2151, 1943, 2125])\n",
    "       \n",
    "instagram =  np.array([2305., 2355., 2203., 2231., 2185., 2420., 2386., 2410., 2340.,\n",
    "       2349., 2241., 2396., 2244., 2267., 2281.])\n",
    "       \n",
    "facebook = np.array([2133., 2522., 2124., 2551., 2293., 2367., 2460., 2311., 2178.,\n",
    "       2113., 2048., 2443., 2265., 2095., 2528.]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fb9487-527f-4a62-8736-845cd8056cb7",
   "metadata": {},
   "source": [
    "According to this information, conduct the hypothesis testing to check whether there is a difference between the average customer acquisition of these three platforms using a 0.05 significance level. If there is a significant difference, perform further analysis to find that caused the difference. Before doing hypothesis testing, check the related assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c850be-9a2d-4f1b-a728-4acf4cbba2d6",
   "metadata": {},
   "source": [
    "## 1. Defining Hypothesis\n",
    "\n",
    "$H_0$: $\\mu_1=\\mu_2=\\mu_3$ (The means of the samples are the same).<br>\n",
    "$H_1$: At least one of them is different.\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "$H_0$: The data is normally distributed.<br>\n",
    "$H_1$: The data is not normally distributed.<br>\n",
    "\n",
    "$H_0$: The variances of the samples are the same.<br>\n",
    "$H_1$: The variances of the samples are different.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b80f3fa5-8839-423f-a2a8-89ad0440cb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0285\n",
      "Reject null hypothesis >> The data are not normally distributed\n",
      "p value:0.4156\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n",
      "p value:0.1716\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(youtube)\n",
    "check_normality(instagram)\n",
    "check_normality(facebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8fef7df-488b-4411-8614-8f5185222b69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0012\n",
      "Reject null hypothesis >> The variances of the samples are different.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(youtube, instagram, facebook)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec417eed-595c-41ec-9fdf-4ef27a84cbb1",
   "metadata": {},
   "source": [
    "## 3. Selecting the Proper Test\n",
    "\n",
    "The normality and variance homogeneity assumptions are not satisfied, therefore we need to use the nonparametric version of ANOVA for unpaired data (the data is collected from different sources).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d9375aaf-c039-41b1-99de-bd39f0bfb482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000015\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "F, p_value = stats.kruskal(youtube, instagram, facebook)\n",
    "print(\"p value:%.6f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cb2cda-a470-408d-8589-2b20f2ba021b",
   "metadata": {},
   "source": [
    "## 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, at least one of the average customer acquisition number is different.   \n",
    "\n",
    "\n",
    "Note: Since, the data is not normal, nonparametric version of posthoc test is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eae05689-27f9-4800-9e34-e85390ae9dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_17b1f_row0_col0, #T_17b1f_row1_col1, #T_17b1f_row1_col2, #T_17b1f_row2_col1, #T_17b1f_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_17b1f_row0_col1, #T_17b1f_row0_col2, #T_17b1f_row1_col0, #T_17b1f_row2_col0 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_17b1f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_17b1f_level0_col0\" class=\"col_heading level0 col0\" >youtube</th>\n",
       "      <th id=\"T_17b1f_level0_col1\" class=\"col_heading level0 col1\" >instagram</th>\n",
       "      <th id=\"T_17b1f_level0_col2\" class=\"col_heading level0 col2\" >facebook</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_17b1f_level0_row0\" class=\"row_heading level0 row0\" >youtube</th>\n",
       "      <td id=\"T_17b1f_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_17b1f_row0_col1\" class=\"data row0 col1\" >0.000010</td>\n",
       "      <td id=\"T_17b1f_row0_col2\" class=\"data row0 col2\" >0.002337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17b1f_level0_row1\" class=\"row_heading level0 row1\" >instagram</th>\n",
       "      <td id=\"T_17b1f_row1_col0\" class=\"data row1 col0\" >0.000010</td>\n",
       "      <td id=\"T_17b1f_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_17b1f_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_17b1f_level0_row2\" class=\"row_heading level0 row2\" >facebook</th>\n",
       "      <td id=\"T_17b1f_row2_col0\" class=\"data row2 col0\" >0.002337</td>\n",
       "      <td id=\"T_17b1f_row2_col1\" class=\"data row2 col1\" >1.000000</td>\n",
       "      <td id=\"T_17b1f_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24232e9f9a0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posthoc_df = sp.posthoc_mannwhitney([youtube,instagram, facebook], p_adjust = 'bonferroni')\n",
    "group_names= [\"youtube\", \"instagram\",\"facebook\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42074f5d-ec33-48ab-b683-282854212395",
   "metadata": {},
   "source": [
    "The average number of customers coming from YouTube is different than the other (actually smaller than the others).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf59ab-657f-4385-bb21-765cb36dbecc",
   "metadata": {},
   "source": [
    "# Q5. t-test dependent\n",
    "\n",
    "The University Health Center diagnosed eighteen students with high cholesterol in the previous semester. Healthcare personnel told these patients about the dangers of high cholesterol and prescribed a diet program. One month later, the patients came for control, and their cholesterol level was reexamined. Test whether there is a difference in the cholesterol levels of the patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ed47c2c7-58de-449b-a528-2a7b1e979339",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_before_diet=np.array([224, 235, 223, 253, 253, 224, 244, 225, 259, 220, 242, 240, 239, 229, 276, 254, 237, 227])\n",
    "test_results_after_diet=np.array([198, 195, 213, 190, 246, 206, 225, 199, 214, 210, 188, 205, 200, 220, 190, 199, 191, 218])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f111fda-8b1e-483f-987e-e0e5f3f9b59c",
   "metadata": {},
   "source": [
    "**According to this information, conduct the hypothesis testing to check whether there is a decrease in the cholesterol levels of the patients after the diet by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113c5524-c2b4-4d1c-889c-dcc478a39469",
   "metadata": {},
   "source": [
    "## 1. Defining Hypothesis\n",
    "\n",
    "$H_0$: $\\mu_d\\geq 0$ or The true mean difference is equal to or bigger than zero.<br>\n",
    "$H_1$: $\\mu_d<0$ or The true mean difference is smaller than zero.\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "- The dependent variable must be continuous (interval/ratio)\n",
    "- The observations are independent of one another.\n",
    "- The dependent variable should be approximately normally distributed.\n",
    "\n",
    "$H_0$: The data are normally distributed.<br>\n",
    "$H_1$: The data are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5678dfa6-cdac-4f3f-ae17-d257e0814806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1635\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n",
      "p value:0.1003\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(test_results_before_diet)\n",
    "check_normality(test_results_after_diet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6932c4d5-cddb-4e11-91cf-3d805b0ae8d9",
   "metadata": {},
   "source": [
    "## 3. Selecting the Proper Test\n",
    "\n",
    "The data is paired since data is collected from the same individuals and assumptions are satisfied, then we can use the dependent t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5ba612e4-bf0e-4546-a592-a1b3d1b716ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.000008 one tailed p value:0.000004\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test_stat, p_value_paired = stats.ttest_rel(test_results_before_diet,test_results_after_diet)\n",
    "print(\"p value:%.6f\" % p_value_paired , \"one tailed p value:%.6f\" %(p_value_paired/2))\n",
    "if p_value_paired <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b447753e-7927-4a92-a82b-c460b37b6543",
   "metadata": {},
   "source": [
    "## 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, there is enough evidence to conclude mean cholesterol level of patients has decreased after the diet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368c832-b2e8-49a4-b0d0-efdd712a0b77",
   "metadata": {},
   "source": [
    "# Q6. Wilcoxon signed-rank test\n",
    "\n",
    "A venture capitalist wanted to invest in a startup that provides data compression without any loss in quality, but there are two competitors: PiedPiper and EndFrame. Initially, she believed the performance of the EndFrame could be better but still wanted to test it before the investment. Then, she gave the same files to each company to compress and recorded their performance scores. The data are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27136d7a-b672-4191-81e4-093e46e5be09",
   "metadata": {},
   "outputs": [],
   "source": [
    "piedpiper=np.array([4.57, 4.55, 5.47, 4.67, 5.41, 5.55, 5.53, 5.63, 3.86, 3.97, 5.44, 3.93, 5.31, 5.17, 4.39, 4.28, 5.25])\n",
    "endframe = np.array([4.27, 3.93, 4.01, 4.07, 3.87, 4.  , 4.  , 3.72, 4.16, 4.1 , 3.9 , 3.97, 4.08, 3.96, 3.96, 3.77, 4.09])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bef637-2204-48a2-8672-7b525f4cf249",
   "metadata": {},
   "source": [
    "**According to this information, conduct the related hypothesis testing by using a 0.05 significance level. Before doing hypothesis testing, check the related assumptions. Comment on the results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b407155-c989-485f-ad4a-cfe54b576b73",
   "metadata": {},
   "source": [
    "## 1. Defining Hypothesis\n",
    "\n",
    "Since the performance scores are obtained from the same files, the data is paired.\n",
    "\n",
    "$H_0$: $\\mu_d\\geq 0$ or The true mean difference is equal to or bigger than zero.<br>\n",
    "$H_1$: $\\mu_d<0$ or The true mean difference is smaller than zero.\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "- The dependent variable must be continuous (interval/ratio)\n",
    "- The observations are independent of one another.\n",
    "- The dependent variable should be approximately normally distributed.\n",
    "\n",
    "$H_0$: The data are normally distributed.<br>\n",
    "$H_1$: The data are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "868c7e7a-cac5-44e2-88e8-941ffbea10a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0304\n",
      "Reject null hypothesis >> The data are not normally distributed\n",
      "p value:0.9587\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n"
     ]
    }
   ],
   "source": [
    "check_normality(piedpiper)\n",
    "check_normality(endframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e86c86-8523-4476-91dd-43e7d2cda4d2",
   "metadata": {},
   "source": [
    "## 3. Selecting the Proper Test\n",
    "\n",
    "The normality assumption is not satisfied; therefore, we need to use the nonparametric version of the paired test, namely the Wilcoxon Signed Rank test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3fdc356e-bbb8-455d-9bf4-808d5ce0d0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value:0.000214 >> one_tailed_pval:0.000107\n",
      "one sided pvalue:0.000107\n",
      "Reject null hypothesis\n"
     ]
    }
   ],
   "source": [
    "test,pvalue = stats.wilcoxon(endframe,piedpiper) ##alternative default two sided\n",
    "print(\"p-value:%.6f\" %pvalue, \">> one_tailed_pval:%.6f\" %(pvalue/2))\n",
    "\n",
    "test,one_sided_pvalue = stats.wilcoxon(endframe,piedpiper, alternative=\"less\")\n",
    "print(\"one sided pvalue:%.6f\" %(one_sided_pvalue))\n",
    "if pvalue <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to recejt null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f3c448-6870-435f-8b1a-b675f3b890ea",
   "metadata": {},
   "source": [
    "## 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, there is enough evidence to conclude that the performance of the PiedPaper is better than the EndFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfc1f35-e537-4c94-9a2d-20f257745443",
   "metadata": {},
   "source": [
    "# Q7. Friedman Chi-Square\n",
    "\n",
    "A researcher was curious about whether there is a difference between the methodology she developed, C, and baseline methods A and B in terms of performance. Therefore, she decided to design different experiments and recorded the achieved accuracy by each method. The below table shows the achieved accuracy on test sets by each method. Please note that the same train and test sets were used for each method.\n",
    "\n",
    "| Experiment |   A  |   B  |   C  |\n",
    "|:----------:|:----:|:----:|:----:|\n",
    "|     E1     | 89.8 | 90.0 | 91.5 |\n",
    "|     E2     | 89.9 | 90.1 | 90.7 |\n",
    "|     E3     | 88.6 | 88.8 | 90.3 |\n",
    "|     E4     | 88.7 | 88.9 | 90.4 |\n",
    "|     E5     | 89.6 | 89.9 | 90.2 |\n",
    "|     E6     | 89.7 | 90.0 | 90.3 |\n",
    "|     E7     | 89.2 | 89.0 | 90.2 |\n",
    "|     E8     | 89.3 | 89.2 | 90.3 | \n",
    "\n",
    "\n",
    "**According to this information, conduct the hypothesis testing to check whether there is a difference between the performance of the methods by using a 0.05 significance level. If there is a significant difference, perform further analysis to find which one caused the difference. Before doing hypothesis testing, check the related assumptions. Comment on the results.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44cf0b2-45d1-426e-92b4-f93eccc1a59f",
   "metadata": {},
   "source": [
    "## 1. Defining Hypothesis\n",
    "\n",
    "$H_0$: $\\mu_1=\\mu_2=\\mu_3$ (The means of the samples are the same).<br>\n",
    "$H_1$: At least one of them is different.\n",
    "\n",
    "## 2. Assumption Check\n",
    "\n",
    "$H_0$: The data is normally distributed.<br>\n",
    "$H_1$: The data is not normally distributed.<br>\n",
    "\n",
    "$H_0$: The variances of the samples are the same.<br>\n",
    "$H_1$: The variances of the samples are different.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "99cf051c-0603-47f4-9192-b082e6378b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.3076\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n",
      "p value:0.0515\n",
      "Fail to reject null hypothesis >> The data are normally distributed\n",
      "p value:0.0016\n",
      "Reject null hypothesis >> The data are not normally distributed\n"
     ]
    }
   ],
   "source": [
    "method_A = np.array([89.8, 89.9, 88.6, 88.7, 89.6, 89.7, 89.2, 89.3])\n",
    "method_B =   np.array([90.0, 90.1, 88.8, 88.9, 89.9, 90.0, 89.0, 89.2])\n",
    "method_C = np.array([91.5, 90.7, 90.3, 90.4, 90.2, 90.3, 90.2, 90.3])\n",
    "\n",
    "check_normality(method_A)\n",
    "check_normality(method_B)\n",
    "check_normality(method_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "36b6a690-37d0-4b51-9ea7-4fe5eb283a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.1953\n",
      "Fail to reject null hypothesis >> The variances of the samples are same.\n"
     ]
    }
   ],
   "source": [
    "stat, pvalue_levene= stats.levene(method_A, method_B, method_C)\n",
    "\n",
    "print(\"p value:%.4f\" % pvalue_levene)\n",
    "if pvalue_levene <0.05:\n",
    "    print(\"Reject null hypothesis >> The variances of the samples are different.\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis >> The variances of the samples are same.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afac3cae-ffb8-4d22-9935-89504e82be90",
   "metadata": {},
   "source": [
    "## 3. Selecting the Proper Test\n",
    "\n",
    "There are three groups, but the normality assumption is violated. So, we need to use the nonparametric version of ANOVA for paired data since the accuracy scores are obtained from the same test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d78144d6-4f8f-4e4f-ac94-59fd5b7b9f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p value:0.0015\n",
      "Reject null hypothesis\n",
      "89.35 89.49 90.49\n"
     ]
    }
   ],
   "source": [
    "test_stat,p_value = stats.friedmanchisquare(method_A,method_B, method_C)\n",
    "print(\"p value:%.4f\" % p_value)\n",
    "if p_value <0.05:\n",
    "    print(\"Reject null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject null hypothesis\")\n",
    "    \n",
    "print(np.round(np.mean(method_A),2), np.round(np.mean(method_B),2), np.round(np.mean(method_C),2))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1fc3ff-ff14-427b-94fd-cfcd4110d964",
   "metadata": {},
   "source": [
    "## 4. Decision and Conclusion\n",
    "\n",
    "At this significance level, at least one of the methods has a different performance.\n",
    "\n",
    "Note: Since the data is not normal, the nonparametric version of the posthoc test is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b893413f-e235-4fce-8bc3-13a55085e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_936d2_row0_col0, #T_936d2_row0_col1, #T_936d2_row1_col0, #T_936d2_row1_col1, #T_936d2_row2_col2 {\n",
       "  background-color: white;\n",
       "}\n",
       "#T_936d2_row0_col2, #T_936d2_row1_col2, #T_936d2_row2_col0, #T_936d2_row2_col1 {\n",
       "  background-color: violet;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_936d2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_936d2_level0_col0\" class=\"col_heading level0 col0\" >Method A</th>\n",
       "      <th id=\"T_936d2_level0_col1\" class=\"col_heading level0 col1\" >Method B</th>\n",
       "      <th id=\"T_936d2_level0_col2\" class=\"col_heading level0 col2\" >Method C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_936d2_level0_row0\" class=\"row_heading level0 row0\" >Method A</th>\n",
       "      <td id=\"T_936d2_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_936d2_row0_col1\" class=\"data row0 col1\" >0.078125</td>\n",
       "      <td id=\"T_936d2_row0_col2\" class=\"data row0 col2\" >0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_936d2_level0_row1\" class=\"row_heading level0 row1\" >Method B</th>\n",
       "      <td id=\"T_936d2_row1_col0\" class=\"data row1 col0\" >0.078125</td>\n",
       "      <td id=\"T_936d2_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_936d2_row1_col2\" class=\"data row1 col2\" >0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_936d2_level0_row2\" class=\"row_heading level0 row2\" >Method C</th>\n",
       "      <td id=\"T_936d2_row2_col0\" class=\"data row2 col0\" >0.023438</td>\n",
       "      <td id=\"T_936d2_row2_col1\" class=\"data row2 col1\" >0.023438</td>\n",
       "      <td id=\"T_936d2_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x24232e7f520>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([method_A, method_B, method_C]) \n",
    "posthoc_df=sp.posthoc_wilcoxon(data, p_adjust=\"holm\")\n",
    "# posthoc_df = sp.posthoc_nemenyi_friedman(data.T) ## another option for the posthoc test\n",
    "\n",
    "group_names= [\"Method A\", \"Method B\",\"Method C\"]\n",
    "posthoc_df.columns= group_names\n",
    "posthoc_df.index= group_names\n",
    "posthoc_df.style.applymap(lambda x: \"background-color:violet\" if x<0.05 else \"background-color: white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7763eaf7-da4c-47a6-994e-8595d37a0166",
   "metadata": {},
   "source": [
    "Method C outperformed others and achieved better accuracy scores than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea4ed59-1e23-4960-9d9a-4c0a49bd5a07",
   "metadata": {},
   "source": [
    "# Q8. The goodness of Fit\n",
    "\n",
    "An analyst of a financial investment company is curious about the relationship between gender and risk appetite. A random sample was taken of 660 customers from the database. The customers in the sample were classified according to their gender and their risk appetite. The result is given in the following table.\n",
    "\n",
    "| **Gender/Risk Appetite** | Very Low | Low | Medium | High | Very High | Total |\n",
    "|:--------------------:|:--------:|:---:|:------:|:----:|:---------:|:-----:|\n",
    "|        **Female**        |    53    |  23 |   30   |  36  |     88    |  230  |\n",
    "|         **Male**         |    71    |  48 |   51   |  57  |    203    |  430  |\n",
    "|         **Total**        |    124   |  71 |   81   |  93  |    291    |  660  |\n",
    "\n",
    "Test the hypothesis that the risk appetite of the customers in this company is independent of their gender. Use $\\alpha = 0.01$.  \n",
    "\n",
    "## 1. Defining Hypothesis\n",
    "\n",
    "$H_{0}$: Gender and risk appetite are independent.   \n",
    "$H_{1}$: Gender and risk appetite are dependent. \n",
    "\n",
    "## 2. Selecting the Proper Test and Assumption Check \n",
    "\n",
    "chi2 test should be used for this question. This test is known as the goodness-of-fit test. It implies that if the observed data are very close to the expected data. The assumption of this test every Ei  5 (in at least 80% of the cells) which is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1d3fe5bd-ca08-49d4-b9af-ec6af4e3c59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected frequencies:\n",
      "  [[ 43.21  24.74  28.23  32.41 101.41]\n",
      " [ 80.79  46.26  52.77  60.59 189.59]]\n",
      "degrees of freedom: 4\n",
      "test stat :7.0942\n",
      "p value:0.1310\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "obs =np.array([[53, 23, 30, 36, 88],[71, 48, 51, 57, 203]])\n",
    "chi2, p, dof, ex = chi2_contingency(obs, correction=False)\n",
    "\n",
    "print(\"expected frequencies:\\n \", np.round(ex,2))\n",
    "print(\"degrees of freedom:\", dof)\n",
    "print(\"test stat :%.4f\" % chi2)\n",
    "print(\"p value:%.4f\" % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4763eb6e-4178-40bd-897c-3568e27c0539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "critical stat:13.2767\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "## calculate critical stat\n",
    "\n",
    "alpha = 0.01\n",
    "df = (5-1)*(2-1)\n",
    "critical_stat = chi2.ppf((1-alpha), df)\n",
    "print(\"critical stat:%.4f\" % critical_stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ce65fd-e40a-48b7-8750-1c99c2df5bfc",
   "metadata": {},
   "source": [
    "## 3. Decision and Conclusion\n",
    "\n",
    "Since $p$-value is larger than $\\alpha=0.01$ (or calculated statistic=7.14 is smaller than the critical statistic=13.28) >> Fail to Reject H0. At this significance level, it can be concluded that gender and risk appetite are independent."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
